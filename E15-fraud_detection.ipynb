{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15\n",
    "\n",
    "# Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "- Fraud Detection Dataset from Microsoft Azure: [data](http://gallery.cortanaintelligence.com/Experiment/8e9fe4e03b8b4c65b9ca947c72b8e463)\n",
    "\n",
    "Fraud detection is one of the earliest industrial applications of data mining and machine learning. Fraud detection is typically handled as a binary classification problem, but the class population is unbalanced because instances of fraud are usually very rare compared to the overall volume of transactions. Moreover, when fraudulent transactions are discovered, the business typically takes measures to block the accounts from transacting to prevent further losses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAge</th>\n",
       "      <th>digitalItemCount</th>\n",
       "      <th>sumPurchaseCount1Day</th>\n",
       "      <th>sumPurchaseAmount1Day</th>\n",
       "      <th>sumPurchaseAmount30Day</th>\n",
       "      <th>paymentBillingPostalCode - LogOddsForClass_0</th>\n",
       "      <th>accountPostalCode - LogOddsForClass_0</th>\n",
       "      <th>paymentBillingState - LogOddsForClass_0</th>\n",
       "      <th>accountState - LogOddsForClass_0</th>\n",
       "      <th>paymentInstrumentAgeInAccount</th>\n",
       "      <th>ipState - LogOddsForClass_0</th>\n",
       "      <th>transactionAmount</th>\n",
       "      <th>transactionAmountUSD</th>\n",
       "      <th>ipPostalCode - LogOddsForClass_0</th>\n",
       "      <th>localHour - LogOddsForClass_0</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>720.25</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>0.421214</td>\n",
       "      <td>1.312186</td>\n",
       "      <td>0.566395</td>\n",
       "      <td>3279.574306</td>\n",
       "      <td>1.218157</td>\n",
       "      <td>599.00</td>\n",
       "      <td>626.164650</td>\n",
       "      <td>1.259543</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>2530.37</td>\n",
       "      <td>0.538996</td>\n",
       "      <td>0.481838</td>\n",
       "      <td>4.401370</td>\n",
       "      <td>4.500157</td>\n",
       "      <td>61.970139</td>\n",
       "      <td>4.035601</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>1185.440000</td>\n",
       "      <td>3.981118</td>\n",
       "      <td>4.921349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.056357</td>\n",
       "      <td>3.155226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.314186</td>\n",
       "      <td>32.09</td>\n",
       "      <td>32.090000</td>\n",
       "      <td>5.008490</td>\n",
       "      <td>4.742303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.331154</td>\n",
       "      <td>3.331239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>133.28</td>\n",
       "      <td>132.729554</td>\n",
       "      <td>1.324925</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>132.73</td>\n",
       "      <td>5.412885</td>\n",
       "      <td>0.342945</td>\n",
       "      <td>5.563677</td>\n",
       "      <td>4.086965</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>543.66</td>\n",
       "      <td>543.660000</td>\n",
       "      <td>2.693451</td>\n",
       "      <td>4.876771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountAge  digitalItemCount  sumPurchaseCount1Day  sumPurchaseAmount1Day  \\\n",
       "0        2000                 0                     0                   0.00   \n",
       "1          62                 1                     1                1185.44   \n",
       "2        2000                 0                     0                   0.00   \n",
       "3           1                 1                     0                   0.00   \n",
       "4           1                 1                     0                   0.00   \n",
       "\n",
       "   sumPurchaseAmount30Day  paymentBillingPostalCode - LogOddsForClass_0  \\\n",
       "0                  720.25                                      5.064533   \n",
       "1                 2530.37                                      0.538996   \n",
       "2                    0.00                                      5.064533   \n",
       "3                    0.00                                      5.064533   \n",
       "4                  132.73                                      5.412885   \n",
       "\n",
       "   accountPostalCode - LogOddsForClass_0  \\\n",
       "0                               0.421214   \n",
       "1                               0.481838   \n",
       "2                               5.096396   \n",
       "3                               5.096396   \n",
       "4                               0.342945   \n",
       "\n",
       "   paymentBillingState - LogOddsForClass_0  accountState - LogOddsForClass_0  \\\n",
       "0                                 1.312186                          0.566395   \n",
       "1                                 4.401370                          4.500157   \n",
       "2                                 3.056357                          3.155226   \n",
       "3                                 3.331154                          3.331239   \n",
       "4                                 5.563677                          4.086965   \n",
       "\n",
       "   paymentInstrumentAgeInAccount  ipState - LogOddsForClass_0  \\\n",
       "0                    3279.574306                     1.218157   \n",
       "1                      61.970139                     4.035601   \n",
       "2                       0.000000                     3.314186   \n",
       "3                       0.000000                     3.529398   \n",
       "4                       0.001389                     3.529398   \n",
       "\n",
       "   transactionAmount  transactionAmountUSD  ipPostalCode - LogOddsForClass_0  \\\n",
       "0             599.00            626.164650                          1.259543   \n",
       "1            1185.44           1185.440000                          3.981118   \n",
       "2              32.09             32.090000                          5.008490   \n",
       "3             133.28            132.729554                          1.324925   \n",
       "4             543.66            543.660000                          2.693451   \n",
       "\n",
       "   localHour - LogOddsForClass_0  Label  \n",
       "0                       4.745402      0  \n",
       "1                       4.921349      0  \n",
       "2                       4.742303      0  \n",
       "3                       4.745402      0  \n",
       "4                       4.876771      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/albahnsen/PracticalMachineLearningClass/master/datasets/15_fraud_detection.csv.zip'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((138721, 16), 797, 0.0057453449730033666)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df.Label.sum(), df.Label.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAge</th>\n",
       "      <th>digitalItemCount</th>\n",
       "      <th>sumPurchaseCount1Day</th>\n",
       "      <th>sumPurchaseAmount1Day</th>\n",
       "      <th>sumPurchaseAmount30Day</th>\n",
       "      <th>paymentBillingPostalCode - LogOddsForClass_0</th>\n",
       "      <th>accountPostalCode - LogOddsForClass_0</th>\n",
       "      <th>paymentBillingState - LogOddsForClass_0</th>\n",
       "      <th>accountState - LogOddsForClass_0</th>\n",
       "      <th>paymentInstrumentAgeInAccount</th>\n",
       "      <th>ipState - LogOddsForClass_0</th>\n",
       "      <th>transactionAmount</th>\n",
       "      <th>transactionAmountUSD</th>\n",
       "      <th>ipPostalCode - LogOddsForClass_0</th>\n",
       "      <th>localHour - LogOddsForClass_0</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>1.387210e+05</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>408.456679</td>\n",
       "      <td>0.865017</td>\n",
       "      <td>1.224018</td>\n",
       "      <td>92.411768</td>\n",
       "      <td>57.280717</td>\n",
       "      <td>3.852491</td>\n",
       "      <td>3.468364</td>\n",
       "      <td>4.427882</td>\n",
       "      <td>4.287014</td>\n",
       "      <td>72.623256</td>\n",
       "      <td>3.806588</td>\n",
       "      <td>2.389925e+03</td>\n",
       "      <td>236.033152</td>\n",
       "      <td>2.816048</td>\n",
       "      <td>4.768151</td>\n",
       "      <td>0.005745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>711.300625</td>\n",
       "      <td>0.604681</td>\n",
       "      <td>11.235396</td>\n",
       "      <td>1105.622216</td>\n",
       "      <td>806.837009</td>\n",
       "      <td>2.023177</td>\n",
       "      <td>2.127371</td>\n",
       "      <td>0.994649</td>\n",
       "      <td>0.992454</td>\n",
       "      <td>271.189458</td>\n",
       "      <td>1.039490</td>\n",
       "      <td>4.998821e+04</td>\n",
       "      <td>998.162648</td>\n",
       "      <td>1.497330</td>\n",
       "      <td>0.363702</td>\n",
       "      <td>0.075580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.154151</td>\n",
       "      <td>-0.154151</td>\n",
       "      <td>0.265703</td>\n",
       "      <td>0.342945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265703</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>0.421214</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.887303</td>\n",
       "      <td>0.716678</td>\n",
       "      <td>3.817305</td>\n",
       "      <td>3.811097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.356462</td>\n",
       "      <td>8.479000e+01</td>\n",
       "      <td>85.190000</td>\n",
       "      <td>1.408767</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>4.422139</td>\n",
       "      <td>4.497450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.114614</td>\n",
       "      <td>1.399900e+02</td>\n",
       "      <td>139.990000</td>\n",
       "      <td>2.929287</td>\n",
       "      <td>4.886641</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>497.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>5.563677</td>\n",
       "      <td>4.992339</td>\n",
       "      <td>0.029861</td>\n",
       "      <td>4.453620</td>\n",
       "      <td>2.395100e+02</td>\n",
       "      <td>199.754240</td>\n",
       "      <td>3.865009</td>\n",
       "      <td>4.962055</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>505.000000</td>\n",
       "      <td>258877.420000</td>\n",
       "      <td>258877.420000</td>\n",
       "      <td>5.412885</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>5.563677</td>\n",
       "      <td>5.561934</td>\n",
       "      <td>4019.593056</td>\n",
       "      <td>4.874212</td>\n",
       "      <td>8.999998e+06</td>\n",
       "      <td>132568.670000</td>\n",
       "      <td>5.008490</td>\n",
       "      <td>5.040929</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accountAge  digitalItemCount  sumPurchaseCount1Day  \\\n",
       "count  138721.000000     138721.000000         138721.000000   \n",
       "mean      408.456679          0.865017              1.224018   \n",
       "std       711.300625          0.604681             11.235396   \n",
       "min         1.000000          0.000000              0.000000   \n",
       "25%         1.000000          1.000000              0.000000   \n",
       "50%         1.000000          1.000000              0.000000   \n",
       "75%       497.000000          1.000000              0.000000   \n",
       "max      2000.000000         29.000000            505.000000   \n",
       "\n",
       "       sumPurchaseAmount1Day  sumPurchaseAmount30Day  \\\n",
       "count          138721.000000           138721.000000   \n",
       "mean               92.411768               57.280717   \n",
       "std              1105.622216              806.837009   \n",
       "min                 0.000000                0.000000   \n",
       "25%                 0.000000                0.000000   \n",
       "50%                 0.000000                0.000000   \n",
       "75%                 0.000000                0.000000   \n",
       "max            258877.420000           258877.420000   \n",
       "\n",
       "       paymentBillingPostalCode - LogOddsForClass_0  \\\n",
       "count                                 138721.000000   \n",
       "mean                                       3.852491   \n",
       "std                                        2.023177   \n",
       "min                                       -0.154151   \n",
       "25%                                        0.887303   \n",
       "50%                                        5.064533   \n",
       "75%                                        5.064533   \n",
       "max                                        5.412885   \n",
       "\n",
       "       accountPostalCode - LogOddsForClass_0  \\\n",
       "count                          138721.000000   \n",
       "mean                                3.468364   \n",
       "std                                 2.127371   \n",
       "min                                -0.154151   \n",
       "25%                                 0.716678   \n",
       "50%                                 5.096396   \n",
       "75%                                 5.096396   \n",
       "max                                 5.096396   \n",
       "\n",
       "       paymentBillingState - LogOddsForClass_0  \\\n",
       "count                            138721.000000   \n",
       "mean                                  4.427882   \n",
       "std                                   0.994649   \n",
       "min                                   0.265703   \n",
       "25%                                   3.817305   \n",
       "50%                                   4.422139   \n",
       "75%                                   5.563677   \n",
       "max                                   5.563677   \n",
       "\n",
       "       accountState - LogOddsForClass_0  paymentInstrumentAgeInAccount  \\\n",
       "count                     138721.000000                  138721.000000   \n",
       "mean                           4.287014                      72.623256   \n",
       "std                            0.992454                     271.189458   \n",
       "min                            0.342945                       0.000000   \n",
       "25%                            3.811097                       0.000000   \n",
       "50%                            4.497450                       0.000000   \n",
       "75%                            4.992339                       0.029861   \n",
       "max                            5.561934                    4019.593056   \n",
       "\n",
       "       ipState - LogOddsForClass_0  transactionAmount  transactionAmountUSD  \\\n",
       "count                138721.000000       1.387210e+05         138721.000000   \n",
       "mean                      3.806588       2.389925e+03            236.033152   \n",
       "std                       1.039490       4.998821e+04            998.162648   \n",
       "min                       0.265703       1.000000e-02              0.000000   \n",
       "25%                       3.356462       8.479000e+01             85.190000   \n",
       "50%                       4.114614       1.399900e+02            139.990000   \n",
       "75%                       4.453620       2.395100e+02            199.754240   \n",
       "max                       4.874212       8.999998e+06         132568.670000   \n",
       "\n",
       "       ipPostalCode - LogOddsForClass_0  localHour - LogOddsForClass_0  \\\n",
       "count                     138721.000000                  138721.000000   \n",
       "mean                           2.816048                       4.768151   \n",
       "std                            1.497330                       0.363702   \n",
       "min                            0.182322                       0.421214   \n",
       "25%                            1.408767                       4.745402   \n",
       "50%                            2.929287                       4.886641   \n",
       "75%                            3.865009                       4.962055   \n",
       "max                            5.008490                       5.040929   \n",
       "\n",
       "               Label  \n",
       "count  138721.000000  \n",
       "mean        0.005745  \n",
       "std         0.075580  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.1\n",
    "\n",
    "Estimate a Logistic Regression and a Decision Tree and Random fOREST\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score\n",
    "* F_Beta-Score (Beta=10)\n",
    "\n",
    "Comment about the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accountAge                                        int64\n",
       "digitalItemCount                                  int64\n",
       "sumPurchaseCount1Day                              int64\n",
       "sumPurchaseAmount1Day                           float64\n",
       "sumPurchaseAmount30Day                          float64\n",
       "paymentBillingPostalCode - LogOddsForClass_0    float64\n",
       "accountPostalCode - LogOddsForClass_0           float64\n",
       "paymentBillingState - LogOddsForClass_0         float64\n",
       "accountState - LogOddsForClass_0                float64\n",
       "paymentInstrumentAgeInAccount                   float64\n",
       "ipState - LogOddsForClass_0                     float64\n",
       "transactionAmount                               float64\n",
       "transactionAmountUSD                            float64\n",
       "ipPostalCode - LogOddsForClass_0                float64\n",
       "localHour - LogOddsForClass_0                   float64\n",
       "Label                                             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Label']\n",
    "X = df.drop(['Label'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    137924\n",
       "1       797\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standarize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# Fit on training set only.\n",
    "scaler.fit(X_train)\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'cumulative explained variance')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA().fit(X_train_s)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 variables explican el 80% de los datos, por lo tanto no es conveniente aplicar PCA sobre los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13439751 0.11322615 0.09854674 0.09204775 0.07350127 0.06884543\n",
      " 0.06683842 0.06272319 0.06024085 0.058123  ]\n",
      "Total explanation:  0.8284903056008428\n"
     ]
    }
   ],
   "source": [
    "# Instanciate a PCA object for the sake of easy visualisation\n",
    "pca = PCA(n_components = 10)\n",
    "# Fit PCA on training set\n",
    "pca.fit(X_train_s)\n",
    "# Apply the mapping (transform) to both the training set and the test set.\n",
    "X_train = pca.transform(X_train_s)\n",
    "X_test = pca.transform(X_test_s)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(\"Total explanation: \",sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9939053693914107\n",
      "F1-score: 0.0\n",
      "F_Beta-Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "lreg = LogisticRegression()\n",
    "lreg.fit(X_train,y_train)\n",
    "y_pred=lreg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_pred, y_test))\n",
    "print(\"F1-score:\",metrics.f1_score(y_pred, y_test))\n",
    "print(\"F_Beta-Score:\",metrics.fbeta_score(y_pred, y_test,10))\n",
    "\n",
    "accuracy_scores.append(['none','reg-log', -1, -1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.988466075407401\n",
      "F1-score: 0.12582781456953643\n",
      "F_Beta-Score: 0.11568952524491334\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train,y_train)\n",
    "y_pred=dtree.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_pred, y_test))\n",
    "print(\"F1-score:\",metrics.f1_score(y_pred, y_test))\n",
    "print(\"F_Beta-Score:\",metrics.fbeta_score(y_pred, y_test,10))\n",
    "\n",
    "accuracy_scores.append(['none','d-tree', -1, -1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9939927476080214\n",
      "F1-score: 0.09836065573770492\n",
      "F_Beta-Score: 0.46259541984732827\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred=rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_pred, y_test))\n",
    "print(\"F1-score:\",metrics.f1_score(y_pred, y_test))\n",
    "print(\"F_Beta-Score:\",metrics.fbeta_score(y_pred, y_test,10))\n",
    "\n",
    "accuracy_scores.append(['none','random forest', -1, -1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.2\n",
    "\n",
    "Under-sample the negative class using random-under-sampling\n",
    "\n",
    "Which is parameter for target_percentage did you choose?\n",
    "How the results change?\n",
    "\n",
    "**Only apply under-sampling to the training set, evaluate using the whole test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UnderSampling(X, y, target_percentage=0.5, seed=None):\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "\n",
    "    n_samples_0_new =  n_samples_1 / target_percentage - n_samples_1\n",
    "    n_samples_0_new_per = n_samples_0_new / n_samples_0\n",
    "\n",
    "    filter_ = y == 0\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    rand_1 = np.random.binomial(n=1, p=n_samples_0_new_per, size=n_samples)\n",
    "    \n",
    "    filter_ = filter_ & rand_1\n",
    "    filter_ = filter_ | (y == 1)\n",
    "    filter_ = filter_.astype(bool)\n",
    "    \n",
    "    return X[filter_], y[filter_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9896238367774913 F1-Score: 0.18524871355060035 F-Beta: 0.17551086082059533\n",
      "Accuracy: 0.9822403774738958 F1-Score: 0.1627188465499485 F-Beta: 0.11418962432915922\n",
      "Accuracy: 0.9669273450128882 F1-Score: 0.11461988304093568 F-Beta: 0.06884367936011128\n",
      "Accuracy: 0.9514614006728123 F1-Score: 0.0952768729641694 F-Beta: 0.05411333714939898\n",
      "Accuracy: 0.9366071038490105 F1-Score: 0.07873015873015873 F-Beta: 0.04352011119798453\n",
      "Accuracy: 0.9065708418891171 F1-Score: 0.06349901467046201 F-Beta: 0.034099772978636714\n",
      "Accuracy: 0.8868888985975796 F1-Score: 0.05579868708971553 F-Beta: 0.029650309397035546\n",
      "Accuracy: 0.8345275022936782 F1-Score: 0.042714520409452804 F-Beta: 0.022339430029774565\n",
      "Accuracy: 0.81401546594434 F1-Score: 0.038400722837135755 F-Beta: 0.020007574212718853\n",
      "Accuracy: 0.77460789025296 F1-Score: 0.032989690721649485 F-Beta: 0.01709600634752711\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for target_percentage in np.arange(0.05,0.55, 0.05):\n",
    "    X_u, y_u = UnderSampling(X_train, y_train, target_percentage, 1)\n",
    "    lreg.fit(X_u,y_u)\n",
    "    y_pred=rf.predict(X_test)\n",
    "    accuracy_scores.append(['under-sampling','reg-log',target_percentage,-1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "    \n",
    "    dtree.fit(X_u,y_u)\n",
    "    y_pred=rf.predict(X_test)\n",
    "    accuracy_scores.append(['under-sampling','d-tree',target_percentage,-1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "    \n",
    "    rf.fit(X_u,y_u)\n",
    "    y_pred=rf.predict(X_test)\n",
    "    accuracy_scores.append(['under-sampling','random forest',target_percentage,-1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "    \n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_pred, y_test),\"F1-Score:\",metrics.f1_score(y_pred, y_test),\"F-Beta:\",metrics.fbeta_score(y_pred, y_test,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.3\n",
    "\n",
    "Same analysis using random-over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def OverSampling(X, y, target_percentage=0.5, seed=None):\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "   \n",
    "    n_samples_1_new =  -target_percentage * n_samples_0 / (target_percentage- 1)\n",
    "    np.random.seed(seed)\n",
    "    filter_ = np.random.choice(X[y == 1].shape[0], int(n_samples_1_new))\n",
    "    # filter_ is within the positives, change to be of all\n",
    "    filter_ = np.nonzero(y == 1)[0][filter_]\n",
    "    filter_ = np.concatenate((filter_, np.nonzero(y == 0)[0]), axis=0)\n",
    "    \n",
    "    return X.iloc[filter_], y.iloc[filter_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9934029446458997 F1-Score: 0.16574585635359118 FBeta: 0.33760445682451257\n",
      "Accuracy: 0.9933811000917472 F1-Score: 0.12680115273775217 FBeta: 0.29725752508361203\n",
      "Accuracy: 0.9932937218751365 F1-Score: 0.13521126760563382 FBeta: 0.2929305135951661\n",
      "Accuracy: 0.993512167416663 F1-Score: 0.15864022662889518 FBeta: 0.35021671826625383\n",
      "Accuracy: 0.9932937218751365 F1-Score: 0.11527377521613831 FBeta: 0.27023411371237455\n",
      "Accuracy: 0.9932063436585259 F1-Score: 0.12394366197183099 FBeta: 0.26851963746223567\n",
      "Accuracy: 0.9933374109834419 F1-Score: 0.11594202898550722 FBeta: 0.27766323024054984\n",
      "Accuracy: 0.9933155664292892 F1-Score: 0.13559322033898305 FBeta: 0.2965137614678899\n",
      "Accuracy: 0.9934247892000524 F1-Score: 0.14245014245014245 FBeta: 0.3206349206349206\n",
      "Accuracy: 0.9934684783083577 F1-Score: 0.138328530259366 FBeta: 0.3242809364548494\n"
     ]
    }
   ],
   "source": [
    "for target_percentage in np.arange(0.05,0.55, 0.05):\n",
    "    \n",
    "    X_u, y_u = OverSampling(X_train, y_train, target_percentage, 42)\n",
    "    lreg.fit(X_u,y_u)\n",
    "    y_pred=rf.predict(X_test)\n",
    "    accuracy_scores.append(['over-sampling','reg-log',target_percentage,-1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "    \n",
    "    dtree.fit(X_u,y_u)\n",
    "    y_pred=rf.predict(X_test)\n",
    "    accuracy_scores.append(['over-sampling','d-tree',target_percentage,-1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "    \n",
    "    rf.fit(X_u,y_u)\n",
    "    y_pred=rf.predict(X_test)\n",
    "    accuracy_scores.append(['over-sampling','random forest',target_percentage,-1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "    \n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_pred, y_test),\"F1-Score:\",metrics.f1_score(y_pred, y_test),\"FBeta:\",metrics.fbeta_score(y_pred, y_test,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.4 (3 points)\n",
    "\n",
    "Evaluate the results using SMOTE\n",
    "\n",
    "Which parameters did you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMOTE(X, y, target_percentage=0.5, k=5, seed=None):\n",
    "    # Calculate the NearestNeighbors\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    nearest_neighbour_ = NearestNeighbors(n_neighbors=k + 1)\n",
    "    nearest_neighbour_.fit(X[y==1])\n",
    "    nns = nearest_neighbour_.kneighbors(X[y==1], \n",
    "                                    return_distance=False)[:, 1:]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "    # New samples\n",
    "    n_samples_1_new =  int(-target_percentage * n_samples_0 / (target_percentage- 1) - n_samples_1)\n",
    "    \n",
    "    # A matrix to store the synthetic samples\n",
    "    new = np.zeros((n_samples_1_new, X.shape[1]))\n",
    "    \n",
    "    # Create seeds\n",
    "    np.random.seed(seed)\n",
    "    seeds = np.random.randint(1, 1000000, 3)\n",
    "    \n",
    "    # Select examples to use as base\n",
    "    np.random.seed(seeds[0])\n",
    "    sel_ = np.random.choice(y[y==1].shape[0], n_samples_1_new)\n",
    "    \n",
    "    # Define random seeds (2 per example)\n",
    "    np.random.seed(seeds[1])\n",
    "    nn__=[]\n",
    "    for i, sel in enumerate(sel_):\n",
    "        nn__.append(np.random.choice(nns[sel]))\n",
    "    \n",
    "    np.random.seed(seeds[2])\n",
    "    steps = np.random.uniform(size=n_samples_1_new)  \n",
    "\n",
    "    # For each selected examples create one synthetic case\n",
    "    for i, sel in enumerate(sel_):\n",
    "        # Select neighbor\n",
    "        nn_ = nn__[i]\n",
    "        step = steps[i]\n",
    "        # Create new sample\n",
    "        new[i, :] = X[y==1].iloc[sel] - step * (X[y==1].iloc[sel] - X[y==1].iloc[nn_])\n",
    "    \n",
    "    X = np.vstack((X, new))\n",
    "    y = np.append(y, np.ones(n_samples_1_new))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9929442090086942 F1-Score: 0.15223097112860892 FBeta: 0.2693333333333333\n",
      "Accuracy: 0.992267027829962 F1-Score: 0.1407766990291262 FBeta: 0.20958855098389978\n",
      "Accuracy: 0.9922888723841147 F1-Score: 0.1493975903614458 FBeta: 0.21933450087565673\n",
      "Accuracy: 0.9908252872558871 F1-Score: 0.1286307053941909 FBeta: 0.1492729439809297\n"
     ]
    }
   ],
   "source": [
    "for target_percentage in [0.25, 0.5]:\n",
    "    for k in [5, 15]:\n",
    "        X_u, y_u = SMOTE(X_train, y_train, target_percentage, k, seed=3)\n",
    "        lreg.fit(X_u,y_u)\n",
    "        y_pred=rf.predict(X_test)\n",
    "        accuracy_scores.append(['SMOTE','reg-log',target_percentage,k,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "\n",
    "        dtree.fit(X_u,y_u)\n",
    "        y_pred=rf.predict(X_test)\n",
    "        accuracy_scores.append(['SMOTE','d-tree',target_percentage,k,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "\n",
    "        rf.fit(X_u,y_u)\n",
    "        y_pred=rf.predict(X_test)\n",
    "        accuracy_scores.append(['SMOTE','random forest',target_percentage,k,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "\n",
    "        print(\"Accuracy:\",metrics.accuracy_score(y_pred, y_test),\"F1-Score:\",metrics.f1_score(y_pred, y_test),\"FBeta:\",metrics.fbeta_score(y_pred, y_test,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.5 (3 points)\n",
    "\n",
    "Evaluate the results using Adaptive Synthetic Sampling Approach for Imbalanced\n",
    "Learning (ADASYN)\n",
    "\n",
    "http://www.ele.uri.edu/faculty/he/PDFfiles/adasyn.pdf\n",
    "https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.ADASYN.html#rf9172e970ca5-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({1: 900, 0: 100})\n",
      "Resampled dataset shape Counter({0: 904, 1: 900})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import ADASYN # doctest: +NORMALIZE_WHITESPACE\n",
    "X, y = make_classification(n_classes=2, class_sep=2,weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0,n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)\n",
    "print('Original dataset shape %s' % Counter(y))\n",
    "\n",
    "ada = ADASYN(random_state=42)\n",
    "X_res, y_res = ada.fit_resample(X, y)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9925946961422517 F1-Score: 0.14609571788413098 FBeta: 0.2347895791583166\n",
      "Accuracy: 0.9925510070339464 F1-Score: 0.16625916870415647 FBeta: 0.2511151736745887\n",
      "Accuracy: 0.9923325614924199 F1-Score: 0.14180929095354525 FBeta: 0.2141864716636197\n",
      "Accuracy: 0.9919830486259775 F1-Score: 0.12410501193317423 FBeta: 0.17894378194207833\n",
      "Accuracy: 0.9925510070339464 F1-Score: 0.13670886075949368 FBeta: 0.22215885947046843\n",
      "Accuracy: 0.9923325614924199 F1-Score: 0.11586901763224182 FBeta: 0.18621242484969938\n",
      "Accuracy: 0.992267027829962 F1-Score: 0.13235294117647056 FBeta: 0.20088397790055249\n",
      "Accuracy: 0.9925510070339464 F1-Score: 0.13231552162849872 FBeta: 0.21747412008281572\n",
      "Accuracy: 0.9929223644545415 F1-Score: 0.15625 FBeta: 0.27114093959731544\n",
      "Accuracy: 0.992703918913015 F1-Score: 0.13020833333333334 FBeta: 0.22595078299776283\n"
     ]
    }
   ],
   "source": [
    "for target_percentage in np.arange(0.05,0.55, 0.05):\n",
    "        ada = ADASYN(random_state=42)\n",
    "        X_u, y_u  = ada.fit_resample(X_train, y_train)\n",
    "            \n",
    "        lreg.fit(X_u,y_u)\n",
    "        y_pred=rf.predict(X_test)\n",
    "        accuracy_scores.append(['ADASYN','reg-log',target_percentage,-1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "\n",
    "        dtree.fit(X_u,y_u)\n",
    "        y_pred=rf.predict(X_test)\n",
    "        accuracy_scores.append(['ADASYN','d-tree',target_percentage,-1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "\n",
    "        rf.fit(X_u,y_u)\n",
    "        y_pred=rf.predict(X_test)\n",
    "        accuracy_scores.append(['ADASYN','random forest',target_percentage,-1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "\n",
    "        print(\"Accuracy:\",metrics.accuracy_score(y_pred, y_test),\"F1-Score:\",metrics.f1_score(y_pred, y_test),\"FBeta:\",metrics.fbeta_score(y_pred, y_test,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores_df=pd.DataFrame(accuracy_scores, columns=['tecnica','algoritmo','target_perc','k','Accuracy','F1-Score','FBeta']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.6 (3 points)\n",
    "\n",
    "Compare and comment about the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tecnica</th>\n",
       "      <th>algoritmo</th>\n",
       "      <th>target_perc</th>\n",
       "      <th>k</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>FBeta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>reg-log</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.993905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>none</td>\n",
       "      <td>d-tree</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.988466</td>\n",
       "      <td>0.125828</td>\n",
       "      <td>0.115690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>random forest</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.993993</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.462595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>under-sampling</td>\n",
       "      <td>reg-log</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.993993</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.462595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>under-sampling</td>\n",
       "      <td>d-tree</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.993993</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.462595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tecnica      algoritmo  target_perc  k  Accuracy  F1-Score     FBeta\n",
       "0            none        reg-log        -1.00 -1  0.993905  0.000000  0.000000\n",
       "1            none         d-tree        -1.00 -1  0.988466  0.125828  0.115690\n",
       "2            none  random forest        -1.00 -1  0.993993  0.098361  0.462595\n",
       "3  under-sampling        reg-log         0.05 -1  0.993993  0.098361  0.462595\n",
       "4  under-sampling         d-tree         0.05 -1  0.993993  0.098361  0.462595"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target_perc</th>\n",
       "      <th>k</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>FBeta</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tecnica</th>\n",
       "      <th>algoritmo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ADASYN</th>\n",
       "      <th>d-tree</th>\n",
       "      <td>0.275</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.992291</td>\n",
       "      <td>0.138040</td>\n",
       "      <td>0.212618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.275</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.992479</td>\n",
       "      <td>0.138197</td>\n",
       "      <td>0.220286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg-log</th>\n",
       "      <td>0.275</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.992291</td>\n",
       "      <td>0.138040</td>\n",
       "      <td>0.212618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">SMOTE</th>\n",
       "      <th>d-tree</th>\n",
       "      <td>0.375</td>\n",
       "      <td>10</td>\n",
       "      <td>0.992742</td>\n",
       "      <td>0.145183</td>\n",
       "      <td>0.255634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.375</td>\n",
       "      <td>10</td>\n",
       "      <td>0.992081</td>\n",
       "      <td>0.142759</td>\n",
       "      <td>0.211882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg-log</th>\n",
       "      <td>0.375</td>\n",
       "      <td>10</td>\n",
       "      <td>0.992742</td>\n",
       "      <td>0.145183</td>\n",
       "      <td>0.255634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">none</th>\n",
       "      <th>d-tree</th>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.988466</td>\n",
       "      <td>0.125828</td>\n",
       "      <td>0.115690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.993993</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.462595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg-log</th>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.993905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">over-sampling</th>\n",
       "      <th>d-tree</th>\n",
       "      <td>0.275</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.971478</td>\n",
       "      <td>0.125259</td>\n",
       "      <td>0.272867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.275</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.993364</td>\n",
       "      <td>0.135793</td>\n",
       "      <td>0.303586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg-log</th>\n",
       "      <td>0.275</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.971478</td>\n",
       "      <td>0.125259</td>\n",
       "      <td>0.272867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">under-sampling</th>\n",
       "      <th>d-tree</th>\n",
       "      <td>0.275</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.926286</td>\n",
       "      <td>0.093537</td>\n",
       "      <td>0.102487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.275</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.904347</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>0.057937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg-log</th>\n",
       "      <td>0.275</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.926286</td>\n",
       "      <td>0.093537</td>\n",
       "      <td>0.102487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              target_perc   k  Accuracy  F1-Score     FBeta\n",
       "tecnica        algoritmo                                                   \n",
       "ADASYN         d-tree               0.275  -1  0.992291  0.138040  0.212618\n",
       "               random forest        0.275  -1  0.992479  0.138197  0.220286\n",
       "               reg-log              0.275  -1  0.992291  0.138040  0.212618\n",
       "SMOTE          d-tree               0.375  10  0.992742  0.145183  0.255634\n",
       "               random forest        0.375  10  0.992081  0.142759  0.211882\n",
       "               reg-log              0.375  10  0.992742  0.145183  0.255634\n",
       "none           d-tree              -1.000  -1  0.988466  0.125828  0.115690\n",
       "               random forest       -1.000  -1  0.993993  0.098361  0.462595\n",
       "               reg-log             -1.000  -1  0.993905  0.000000  0.000000\n",
       "over-sampling  d-tree               0.275  -1  0.971478  0.125259  0.272867\n",
       "               random forest        0.275  -1  0.993364  0.135793  0.303586\n",
       "               reg-log              0.275  -1  0.971478  0.125259  0.272867\n",
       "under-sampling d-tree               0.275  -1  0.926286  0.093537  0.102487\n",
       "               random forest        0.275  -1  0.904347  0.087000  0.057937\n",
       "               reg-log              0.275  -1  0.926286  0.093537  0.102487"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_scores_df.groupby(['tecnica', 'algoritmo']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>FBeta</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tecnica</th>\n",
       "      <th>target_perc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">ADASYN</th>\n",
       "      <th>0.05</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.991415</td>\n",
       "      <td>0.134452</td>\n",
       "      <td>0.177778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.992580</td>\n",
       "      <td>0.152817</td>\n",
       "      <td>0.240231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.15</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.992478</td>\n",
       "      <td>0.158109</td>\n",
       "      <td>0.238806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.20</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.992216</td>\n",
       "      <td>0.135908</td>\n",
       "      <td>0.202439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.992172</td>\n",
       "      <td>0.128306</td>\n",
       "      <td>0.193349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.30</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.992478</td>\n",
       "      <td>0.129762</td>\n",
       "      <td>0.210177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.35</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.992311</td>\n",
       "      <td>0.121364</td>\n",
       "      <td>0.191103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.40</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.992362</td>\n",
       "      <td>0.132340</td>\n",
       "      <td>0.206414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.45</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.992675</td>\n",
       "      <td>0.140294</td>\n",
       "      <td>0.235363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.992850</td>\n",
       "      <td>0.147569</td>\n",
       "      <td>0.256078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SMOTE</th>\n",
       "      <th>0.25</th>\n",
       "      <td>10</td>\n",
       "      <td>0.993006</td>\n",
       "      <td>0.145688</td>\n",
       "      <td>0.277692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>10</td>\n",
       "      <td>0.992038</td>\n",
       "      <td>0.143063</td>\n",
       "      <td>0.204409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <th>-1.00</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.992121</td>\n",
       "      <td>0.074729</td>\n",
       "      <td>0.192762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">over-sampling</th>\n",
       "      <th>0.05</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.847540</td>\n",
       "      <td>0.077242</td>\n",
       "      <td>0.123932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.993396</td>\n",
       "      <td>0.152764</td>\n",
       "      <td>0.324155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.15</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.993352</td>\n",
       "      <td>0.129605</td>\n",
       "      <td>0.295815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.20</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.993367</td>\n",
       "      <td>0.143021</td>\n",
       "      <td>0.312026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.993439</td>\n",
       "      <td>0.144185</td>\n",
       "      <td>0.323556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.30</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.993265</td>\n",
       "      <td>0.118164</td>\n",
       "      <td>0.269663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.35</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.993250</td>\n",
       "      <td>0.121276</td>\n",
       "      <td>0.271568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.40</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.993330</td>\n",
       "      <td>0.122492</td>\n",
       "      <td>0.283947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.45</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.993352</td>\n",
       "      <td>0.137879</td>\n",
       "      <td>0.304554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.993439</td>\n",
       "      <td>0.141076</td>\n",
       "      <td>0.321850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">under-sampling</th>\n",
       "      <th>0.05</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.992536</td>\n",
       "      <td>0.127323</td>\n",
       "      <td>0.366901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.987163</td>\n",
       "      <td>0.177739</td>\n",
       "      <td>0.155070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.15</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.977136</td>\n",
       "      <td>0.146686</td>\n",
       "      <td>0.099074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.20</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.961772</td>\n",
       "      <td>0.108172</td>\n",
       "      <td>0.063934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.946510</td>\n",
       "      <td>0.089761</td>\n",
       "      <td>0.050582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.30</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.926595</td>\n",
       "      <td>0.073653</td>\n",
       "      <td>0.040380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.35</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.900010</td>\n",
       "      <td>0.060932</td>\n",
       "      <td>0.032617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.40</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.869435</td>\n",
       "      <td>0.051437</td>\n",
       "      <td>0.027213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.45</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.827690</td>\n",
       "      <td>0.041277</td>\n",
       "      <td>0.021562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.800880</td>\n",
       "      <td>0.036597</td>\n",
       "      <td>0.019037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             k  Accuracy  F1-Score     FBeta\n",
       "tecnica        target_perc                                  \n",
       "ADASYN          0.05        -1  0.991415  0.134452  0.177778\n",
       "                0.10        -1  0.992580  0.152817  0.240231\n",
       "                0.15        -1  0.992478  0.158109  0.238806\n",
       "                0.20        -1  0.992216  0.135908  0.202439\n",
       "                0.25        -1  0.992172  0.128306  0.193349\n",
       "                0.30        -1  0.992478  0.129762  0.210177\n",
       "                0.35        -1  0.992311  0.121364  0.191103\n",
       "                0.40        -1  0.992362  0.132340  0.206414\n",
       "                0.45        -1  0.992675  0.140294  0.235363\n",
       "                0.50        -1  0.992850  0.147569  0.256078\n",
       "SMOTE           0.25        10  0.993006  0.145688  0.277692\n",
       "                0.50        10  0.992038  0.143063  0.204409\n",
       "none           -1.00        -1  0.992121  0.074729  0.192762\n",
       "over-sampling   0.05        -1  0.847540  0.077242  0.123932\n",
       "                0.10        -1  0.993396  0.152764  0.324155\n",
       "                0.15        -1  0.993352  0.129605  0.295815\n",
       "                0.20        -1  0.993367  0.143021  0.312026\n",
       "                0.25        -1  0.993439  0.144185  0.323556\n",
       "                0.30        -1  0.993265  0.118164  0.269663\n",
       "                0.35        -1  0.993250  0.121276  0.271568\n",
       "                0.40        -1  0.993330  0.122492  0.283947\n",
       "                0.45        -1  0.993352  0.137879  0.304554\n",
       "                0.50        -1  0.993439  0.141076  0.321850\n",
       "under-sampling  0.05        -1  0.992536  0.127323  0.366901\n",
       "                0.10        -1  0.987163  0.177739  0.155070\n",
       "                0.15        -1  0.977136  0.146686  0.099074\n",
       "                0.20        -1  0.961772  0.108172  0.063934\n",
       "                0.25        -1  0.946510  0.089761  0.050582\n",
       "                0.30        -1  0.926595  0.073653  0.040380\n",
       "                0.35        -1  0.900010  0.060932  0.032617\n",
       "                0.40        -1  0.869435  0.051437  0.027213\n",
       "                0.45        -1  0.827690  0.041277  0.021562\n",
       "                0.50        -1  0.800880  0.036597  0.019037"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_scores_df.groupby(['tecnica', 'target_perc']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target_perc</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>FBeta</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tecnica</th>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADASYN</th>\n",
       "      <th>-1</th>\n",
       "      <td>0.275</td>\n",
       "      <td>0.992354</td>\n",
       "      <td>0.138092</td>\n",
       "      <td>0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SMOTE</th>\n",
       "      <th>5</th>\n",
       "      <td>0.375</td>\n",
       "      <td>0.992784</td>\n",
       "      <td>0.143307</td>\n",
       "      <td>0.259401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.375</td>\n",
       "      <td>0.992260</td>\n",
       "      <td>0.145444</td>\n",
       "      <td>0.222700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <th>-1</th>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.992121</td>\n",
       "      <td>0.074729</td>\n",
       "      <td>0.192762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>over-sampling</th>\n",
       "      <th>-1</th>\n",
       "      <td>0.275</td>\n",
       "      <td>0.978773</td>\n",
       "      <td>0.128770</td>\n",
       "      <td>0.283107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>under-sampling</th>\n",
       "      <th>-1</th>\n",
       "      <td>0.275</td>\n",
       "      <td>0.918973</td>\n",
       "      <td>0.091358</td>\n",
       "      <td>0.087637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    target_perc  Accuracy  F1-Score     FBeta\n",
       "tecnica        k                                             \n",
       "ADASYN         -1         0.275  0.992354  0.138092  0.215174\n",
       "SMOTE           5         0.375  0.992784  0.143307  0.259401\n",
       "                15        0.375  0.992260  0.145444  0.222700\n",
       "none           -1        -1.000  0.992121  0.074729  0.192762\n",
       "over-sampling  -1         0.275  0.978773  0.128770  0.283107\n",
       "under-sampling -1         0.275  0.918973  0.091358  0.087637"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_scores_df.groupby(['tecnica', 'k']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando los resutados, la tecnica que da mejores resultados es SMOTE, considerando que todas tienen un Accuracy alto debido al desbalanceo de las clases. Dado que en nuestro caso, el costo de falsos negativos es peor que el costo de los falsos positivos, se realzia el ranking con base en el F1-Score, obteniendo el "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

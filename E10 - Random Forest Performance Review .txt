El trabajo de investigación plantea como escoger el mejor algoritmo o modelo para escoger un problema de clasificación.
La investigación realiza una comparación de 179 clasificadores de 17 familias (discriminant analysis, Bayesian methods, neural networks, decision trees, rule-based methods, boosting, bagging, stacking, random forest, otros métodos de ensemble, generalized linear models, nearest neighbor methods, partial least squares and principal component regression, logistic and multinomial regression, multivariate adaptive regression splines, y otros métodos), implementados en Weka, R, C y Matlab, haciendo uso de  121 datasets, con tamaños entre 10 y 130000 registros, entre 3 y 262 variables, y entre 2 y 100 clases. 
Se plantea que la decisión de escoger el mejor algoritmo de clasificador en muchas ocasiones está sesgada al conocimiento y formación que se tenga, lo que conlleva a que nos siempre se elija al mejor clasificador, sumado a que generalmente los trabajaos de comparación de rendimiento de modelos se limitan a hacerlo entre una misma familia. Otro factor a tener en cuenta es que los modelos podrían variar su rendimiento dependiendo del dataset con el que se enfrenten.
El objetivo de la investigación es encontrar cual clasificador probablemente tenga un mejor rendimiento frente a cualquier dataset, ranquearlos por clasificador y familia en términos de precisión y evaluar el comportamiento variando propiedades del dataset . El documento realiza una descripción de todos los datasets utilizados y sus principales características (# de registros, variables y clases, y el porcentaje de la clase mayoritaria). Se observa que los dataset presentan mucha variedad en estos parámetros. Ta bien se presentan los clasificadores usados y una breve descripción de funcionamiento, se observan algoritmos clásicos con muchas variaciones.
El clasificador que dio mejores resultados fue el random forest implementado en R, frente a otros modelos mucho más nuevos. El segundo fue el SVM con kernel gaussiano y kernel polinomial .
	

